<details>
    <summary>1. 캐시 메모리가 필요한 이유와 지역성 원리를 설명해주세요</summary>
    <br>

**캐시 메모리**는 CPU와 메인 메모리 간의 속도 차이를 해결하기 위해 반드시 필요한 **고속 임시 저장소**입니다.

CPU는 현대에 들어 엄청나게 빨라졌지만, 메인 메모리인 RAM은 상대적으로 느립니다. CPU가 데이터를 요청할 때마다 RAM까지 가서 가져오면 CPU는 계속 기다려야 하는 병목현상이 발생합니다. 이 문제를 해결하기 위해 CPU 가까이에 아주 빠른 캐시 메모리를 두어서 자주 사용하는 데이터를 미리 복사해 놓는 것입니다.

캐시가 효과적으로 작동할 수 있는 이유는 프로그램 실행에 일정한 패턴인 '지역성 원리'가 있기 때문입니다.

**시간 지역성**은 최근에 사용한 데이터를 다시 사용할 가능성이 높다는 특성입니다. 예를 들어 반복문에서 변수 i를 계속 참조하거나, 함수에서 지역변수를 반복 사용하는 경우입니다.

**공간 지역성**은 현재 접근한 데이터 주변의 데이터도 곧 사용될 가능성이 높다는 특성입니다. 배열을 순차적으로 처리할 때 arr[0] 다음에 arr[1], arr[2]를 사용하는 것이 대표적인 예시입니다.

이 두 지역성 덕분에 캐시에 데이터를 저장해두면 캐시 적중률이 높아져서, CPU가 메인 메모리까지 가지 않고도 필요한 데이터를 빠르게 가져올 수 있습니다. 결과적으로 전체 시스템 성능이 크게 향상됩니다.

</details>

<details>
    <summary>2. 시간 지역성과 공간 지역성의 차이점과 예시를 들어주세요.</summary>
    <br>

시간 지역성과 공간 지역성은 메모리 접근 패턴에서 서로 다른 특성을 보여줍니다.

**시간 지역성**은 '언제'에 관한 개념으로, 한 번 접근한 데이터를 가까운 시간 내에 다시 접근할 가능성이 높다는 특성입니다.

```java
for(int i = 0; i< 1000;i++){
    sum += array[i]; // 변수 sum과 i가 반복적으로 사용됨
}
```

여기서 변수 sum과 i는 루프가 실행되는 동안 계속 해서 반복 접근되므로 시간 지역성을 보여줍니다.
**공간 지역성**은 '어디서'에 관한 개념으로 , 현재 접근한 메모리 위치 근처의 데이터들이 곧 사용될 가능성이 높다는 특성입니다.

```java
int array[1000];
for(int i =0; i<1000;i++){
    array[i] = i*2 // 배열을 순차적으로 접근
}
```

배열 원소들이 메모리에 연속적으로 배치되어 있고, array[0].array[1] 순서로 접근하므로 공간 지역성을 보여줍니다.

즉 핵심 차이점은
**시간 지역성**: **같은** 데이터를 **'다시'** 사용하는 패턴
**공간 지역성**: **인접한** 데이터를 **'연달아'** 사용하는 패턴 입니다.
이 두 지역성 덕분에 캐시는 최근 사용된 데이터 뿐만 아니라 그 주변 데이터까지 함께 가져와서 향후 메모리 접근 요청을 빠르게 처리할 수 있습니다.

</details>

<details>
    <summary>3. L1,L2,L3 캐시의 특징과 CPU와의 거리 관계를 설명해주세요.</summary>
    <br>

CPU 캐시는 계층적 구조로 설계되어 있으며, 숫자가 낮을수록 CPU에 물리적으로 더 가깝게 위치합니다.

**L1 캐시(1차 캐시)** 는 CPU 코어 내부에 직접 내장되어 있어서 가장 빠른 접근 속도를 자랑합니다. 용량은 보통 32KB~64KB로 가장 작지만, 1-2 클록 사이클 내에 데이터에 접근할 수 있습니다. 각 CPU 코어마다 독립적으로 가지고 있으며, 보통 명령어용(I-cache)과 데이터용(D-cache)으로 분리되어 있습니다.

**L2 캐시 (2차 캐시)** 는 CPU 코어와 가까운 위치에 있지만 L1보다는 조금 멀리 배치됩니다. 용량은 256KB~1MB 정도로 L1보다 크고, 접근 속도는 3-10 클록 사이클 정도입니다. 각 코어마다 전용으로 할당되는 경우가 많습니다.

**L3 캐시 (3차 캐시)** 는 여러 CPU 코어들이 공유하는 캐시로, 상대적으로 가장 멀리 위치합니다. 용량은 8MB~32MB로 가장 크지만, 접근 속도는 10-50 클록 사이클로 가장 느립니다. 멀티코어 환경에서 코어 간 데이터 공유 역할을 담당합니다.

**계층적 동작 원리**:
CPU가 데이터를 요청하면 L1 → L2 → L3 → 메인 메모리 순서로 찾아갑니다. 상위 캐시에서 데이터를 찾으면(캐시 히트) 즉시 반환하고, 없으면 하위 레벨로 내려가서 찾습니다.
이런 계층 구조 덕분에 속도와 용량, 비용의 균형을 맞출 수 있어서 전체적인 시스템 성능을 최적화할 수 있습니다.

</details>

<details>
    <summary>4. 캐시 히트와 캐시 미스의 차이점과 성능에 미치는 영향을 설명해주세요.</summary>
    <br>

캐시 히트와 캐시 미스는 CPU가 데이터를 요청했을 때 캐시에서 해당 데이터를 찾을 수 있는지 여부에 따라 결정됩니다.

**캐시 히트** 는 CPU가 필요한 데이터가 캐시에 이미 존재하는 경우 입니다.
이 때는 메인 메모리까지 가지 않고 캐시에서 바로 데이터를 가져올 수 있어서 매우 빠른 처리가 가능합니다.
L1 캐시에서 히트되면 1-2 클록 사이클 내에 데이터를 얻을 수 있습니다.
**캐시 미스** 는 필요한 데이터가 캐시에 없어서 하위 메모리 계층 내려가야 하는 경우 입니다.
최악의 경우 메인 메로리까지 접근해야 하는데, 이때는 수십에서 수백 클록 사이클이 걸릴 수 있습니다.

성능에 미치는 영향에는 **캐시 히트율**이 90%라면, 10번 중 9번은 빠르게 처리되고 1번만 느리게 처리 됩니다.
하지만 **캐시미스**가 발생하면 메인 메모리 접근으로 인해 10-100배 이상 느려질 수 있어서 전체 성능에 치명적인 영향을 줍니다.

실제로 캐시 히트율이 95%에서 90%로 5% 떨어지면, 시스템 전체 성능이 체감상 절반 가까이 느려질 수 있습니다.

</details>

<details>
    <summary>5. Cold Miss, Capacity Miss, Conflict Miss의 발생 원인과 예시를 설명해주세요.</summary>
    <br>

캐시 미스는 **발생 원인**에 따라 세 가지 유형으로 나뉘며, 각각 다른 상황에서 발생합니다.

**Cold Miss는 캐시가 비어 있거나 처음 접근하는 데이터 때문에 발생하는 피할 수 없는 미스입니다.**<br>
프로그램이 시작될 때나 새로운 배열에 처음 접근할 때 반드시 발생합니다. 예를 들어 int arr[1000]; int first = arr[0]; 코드에서 arr[0]에 처음 접근하는 순간에는 캐시에 아무것도 없기 때문에 무조건 메모리에서 가져와야 합니다.
이는 시스템의 구조적 특성이므로 완전히 막을 수는 없습니다.

**Capacity Miss는 캐시 용량이 부족해서 예전 데이터가 밀려나고 나중에 다시 필요할 때 발생하는 미스입니다.**
작업하는 데이터 크기가 캐시보다 클 때 생깁니다. 예를 들어 32KB 캐시에서 100KB 배열을 순회하면 처음에는 캐시에 저장되지만, 배열이 커서 앞쪽 데이터들이 계속 밀려나게 됩니다.
나중에 big_array[0]에 접근하려고 하면 이미 캐시에서 사라져서 다시 메모리에서 가져와야 합니다.

**Conflict Miss는 캐시의 매핑 구조 때문에 서로 다른 데이터가 같은 캐시 라인을 놓고 경쟁해서 발생하는 미스입니다.**
Direct Mapping캐시에서 주로 발생하며, 예를들어 array1[0]과 array2[0]이 캐시의 동일한 라인에 매핑된다면, 하나를 접근한 후 다른 하나를 접근하면 이전 데이터가 사라져서 다시 원래 데이터에 접근할 때 미스가 발생합니다.

</details>

<details>
    <summary>6. 직접 매핑, 연관 매핑, 집합 연관 매핑의 장단점을 비교해주세요.</summary>
    <br>

캐시 매핑 방식은 메모리 블록을 캐시의 어느 위치에 저장할지 결정하는 규칙이며, 각각 다른 특성을 가집니다.

**직접 매핑(Direct Mapping)은 가장 단순하고 빠른 방식입니다.**
메모리 주소를 캐시 라인 수로 나눈 나머지로 위치를 결정하기 때문에 하드웨어 구현이 매우 간단하고 검색 속도가 빠릅니다. 하지만 서로 다른 메모리 블록이 같은 캐시 라인에 매핑되면 계속 서로 덮어쓰면서 Conflict Miss가 자주 발생합니다. 예를 들어 배열 두 개가 우연히 같은 캐시 라인들을 사용하게 되면 번갈아 접근할 때마다 미스가 발생해서 성능이 크게 떨어집니다.

**연관 매핑(Associative Mapping)은 가장 유연한 방식으로 어떤 메모리 블록이든 캐시의 아무 위치에나 저장할 수 있습니다.**
이 때문에 Conflict Miss가 거의 발생하지 않고 캐시 공간을 최대한 효율적으로 활용할 수 있습니다. 하지만 데이터를 찾을 때 모든 캐시 라인을 검사해야 하므로 하드웨어가 복잡해지고 전력 소모가 크며 접근 시간도 오래 걸립니다. 특히 캐시 크기가 클수록 검색 비용이 기하급수적으로 증가합니다.

**집합 연관 매핑(Set-Associative Mapping)은 앞의 두 방식의 장점을 결합한 절충안입니다.**
캐시를 여러 세트로 나누고, 각 세트 내에서는 연관 매핑을 사용합니다. 4-way 세트 연관이라면 특정 세트 내 4개 위치 중 아무 곳에나 저장할 수 있어서 Conflict Miss를 크게 줄이면서도 검색 범위를 제한해서 하드웨어 복잡도를 적절히 유지합니다. 현대 CPU 캐시 대부분이 이 방식을 채택하는 이유는 성능과 비용의 균형이 가장 좋기 때문입니다.

</details>
